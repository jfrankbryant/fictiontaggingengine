{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#based on the variability of tags, it'll be most efficient to download csvs from AO3 and append the story text \n",
    "soup_0005 = BeautifulSoup(open('Fanfic_HTML/0005.html'), \"html.parser\")\n",
    "soup_13Heirs = BeautifulSoup(open('Fanfic_HTML/13 Heirs.html'), \"html.parser\")\n",
    "soup_WizardComes = BeautifulSoup(open('Fanfic_HTML/In Which A Wizard Comes.html'), \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json data = \n",
    "Title\n",
    "AO3 link\n",
    "Rating\n",
    "Warning\n",
    "Audience Category\n",
    "Fandom(s)\n",
    "Characters\n",
    "Tags\n",
    "Series\n",
    "Collections\n",
    "Publish Date\n",
    "Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def extractTagsClass(soup_obj):\\n    #code to extract metadata (fandom, characters, tags, warning, etc.)\\n    i = 0\\n    for element in soup_obj.find(class_=\"tags\"):\\n        if i == 3:\\n            story_rating = element.string\\n        elif i == 7:\\n            story_archive_warning = element.string\\n        elif i == 11:\\n            story_category = element.string\\n        elif i == 15:\\n            raw_fandom_text = element.find_all(\\'a\\')\\n            for obj in raw_fandom_text:\\n                fandom_text += obj.string + \", \"\\n            fandom_text = fandom_text[:-2]\\n        elif i == 19:\\n            story_character = element.string\\n        elif i == 23:\\n            additionalTags = element.find_all(\\'a\\')\\n            for obj in additionalTags:\\n                additionalTags_text += obj.string + \", \"\\n            additionalTags_text = additionalTags_text[:-2]\\n        elif i == 27:\\n            story_series_name = element.find(\\'a\\').string\\n        elif i == 31:\\n            story_collections = element.string\\n        elif i == 35:\\n            pub_stat = str(element.string).strip()\\n            story_publish_date = pub_stat[11:21]\\n            story_word_count = pub_stat[37:40]\\n        i += 1\\n   \\n    return story_character, fandom_text, additionalTags_text, story_rating, story_archive_warning, story_category, story_series_name, story_collections, story_publish_date, story_word_count'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractFandoms(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    fandom_text = \"\"\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 16:\n",
    "            raw_fandom_text = element.find_all('a')\n",
    "            for obj in raw_fandom_text:\n",
    "                fandom_text += obj.string + \", \"\n",
    "            fandom_text = fandom_text[:-2]\n",
    "        else:\n",
    "            continue\n",
    "        return fandom_text\n",
    "            \n",
    "def extractAddTags(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    additionalTags_text = \"\"\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 24:\n",
    "            additionalTags = element.find_all('a')\n",
    "            for obj in additionalTags:\n",
    "                additionalTags_text += obj.string + \", \"\n",
    "            additionalTags_text = additionalTags_text[:-2]\n",
    "        else:\n",
    "            continue\n",
    "    return additionalTags_text\n",
    "    \n",
    "def extractStoryRating(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 4:\n",
    "            story_rating = element.string\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "def extractArchiveWarning(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 8:\n",
    "            story_archive_warning = element.string\n",
    "        else:\n",
    "            continue\n",
    "    return story_archive_warning\n",
    "            \n",
    "def extractCategory(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 12:\n",
    "            story_category = element.string\n",
    "        else:\n",
    "            continue\n",
    "    return story_category\n",
    "            \n",
    "def extractCharacters(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 20:\n",
    "            story_character = element.string\n",
    "        else:\n",
    "            continue\n",
    "    return story_character\n",
    "            \n",
    "def extractSeries(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 28:\n",
    "            story_series_name = element.find('a').string\n",
    "        else:\n",
    "            continue\n",
    "    return story_series_name\n",
    "    \n",
    "def extractCollections(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        if i == 32:\n",
    "            story_collections = element.string\n",
    "        else:\n",
    "            continue\n",
    "    return story_collections\n",
    "\n",
    "def extractPubStats(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        i += 1\n",
    "        print(i)\n",
    "        print(element)\n",
    "        if i == 36:\n",
    "            pub_stat = str(element.string).strip()\n",
    "            print(pub_stat)\n",
    "            #story_publish_date = pub_stat[11:21]\n",
    "            #story_word_count = pub_stat[37:40]\n",
    "        else:\n",
    "            continue\n",
    "        return pub_stat #story_publish_date, story_word_count\n",
    "                       \n",
    "\"\"\"def extractTagsClass(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        if i == 3:\n",
    "            story_rating = element.string\n",
    "        elif i == 7:\n",
    "            story_archive_warning = element.string\n",
    "        elif i == 11:\n",
    "            story_category = element.string\n",
    "        elif i == 15:\n",
    "            raw_fandom_text = element.find_all('a')\n",
    "            for obj in raw_fandom_text:\n",
    "                fandom_text += obj.string + \", \"\n",
    "            fandom_text = fandom_text[:-2]\n",
    "        elif i == 19:\n",
    "            story_character = element.string\n",
    "        elif i == 23:\n",
    "            additionalTags = element.find_all('a')\n",
    "            for obj in additionalTags:\n",
    "                additionalTags_text += obj.string + \", \"\n",
    "            additionalTags_text = additionalTags_text[:-2]\n",
    "        elif i == 27:\n",
    "            story_series_name = element.find('a').string\n",
    "        elif i == 31:\n",
    "            story_collections = element.string\n",
    "        elif i == 35:\n",
    "            pub_stat = str(element.string).strip()\n",
    "            story_publish_date = pub_stat[11:21]\n",
    "            story_word_count = pub_stat[37:40]\n",
    "        i += 1\n",
    "   \n",
    "    return story_character, fandom_text, additionalTags_text, story_rating, story_archive_warning, story_category, story_series_name, story_collections, story_publish_date, story_word_count\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "37\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(soup_0005.find(class_=\"tags\")))\n",
    "print(len(soup_13Heirs.find(class_=\"tags\")))\n",
    "print(len(soup_WizardComes.find(class_=\"tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "2\n",
      "<dt>Rating:</dt>\n",
      "3\n",
      "\n",
      "\n",
      "4\n",
      "<dd><a href=\"http://archiveofourown.org/tags/General%20Audiences\">General Audiences</a></dd>\n",
      "5\n",
      "\n",
      "\n",
      "6\n",
      "<dt>Archive Warning:</dt>\n",
      "7\n",
      "\n",
      "\n",
      "8\n",
      "<dd><a href=\"http://archiveofourown.org/tags/No%20Archive%20Warnings%20Apply\">No Archive Warnings Apply</a></dd>\n",
      "9\n",
      "\n",
      "\n",
      "10\n",
      "<dt>Category:</dt>\n",
      "11\n",
      "\n",
      "\n",
      "12\n",
      "<dd><a href=\"http://archiveofourown.org/tags/F*s*M\">F/M</a></dd>\n",
      "13\n",
      "\n",
      "\n",
      "14\n",
      "<dt>Fandom:</dt>\n",
      "15\n",
      "\n",
      "\n",
      "16\n",
      "<dd><a href=\"http://archiveofourown.org/tags/Howl%E2%80%99s%20Moving%20Castle\">Howl’s Moving Castle</a>, <a href=\"http://archiveofourown.org/tags/Howl%20no%20Ugoku%20Shiro%20%7C%20Howl's%20Moving%20Castle\">Howl no Ugoku Shiro | Howl's Moving Castle</a>, <a href=\"http://archiveofourown.org/tags/Howl%20Series%20-%20Diana%20Wynne%20Jones\">Howl Series - Diana Wynne Jones</a>, <a href=\"http://archiveofourown.org/tags/Howl's%20Moving%20Castle%20-%20All%20Media%20Types\">Howl's Moving Castle - All Media Types</a></dd>\n",
      "17\n",
      "\n",
      "\n",
      "18\n",
      "<dt>Relationship:</dt>\n",
      "19\n",
      "\n",
      "\n",
      "20\n",
      "<dd><a href=\"http://archiveofourown.org/tags/Sophie%20Hatter*s*Howl%20Pendragon\">Sophie Hatter/Howl Pendragon</a>, <a href=\"http://archiveofourown.org/tags/Calcifer%20*a*%20Howl%20Pendragon\">Calcifer &amp; Howl Pendragon</a>, <a href=\"http://archiveofourown.org/tags/Calcifer%20*a*%20Sophie%20Hatter%20*a*%20Howl%20Pendragon\">Calcifer &amp; Sophie Hatter &amp; Howl Pendragon</a>, <a href=\"http://archiveofourown.org/tags/Calcifer%20*a*%20Sophie%20Hatter\">Calcifer &amp; Sophie Hatter</a></dd>\n",
      "21\n",
      "\n",
      "\n",
      "22\n",
      "<dt>Character:</dt>\n",
      "23\n",
      "\n",
      "\n",
      "24\n",
      "<dd><a href=\"http://archiveofourown.org/tags/Calcifer%20(Howl%20Series)\">Calcifer (Howl Series)</a>, <a href=\"http://archiveofourown.org/tags/Howl%20Pendragon\">Howl Pendragon</a>, <a href=\"http://archiveofourown.org/tags/Sophie%20Hatter\">Sophie Hatter</a></dd>\n",
      "25\n",
      "\n",
      "\n",
      "26\n",
      "<dt>Additional Tags:</dt>\n",
      "27\n",
      "\n",
      "\n",
      "28\n",
      "<dd><a href=\"http://archiveofourown.org/tags/One%20Shot\">One Shot</a>, <a href=\"http://archiveofourown.org/tags/Lemon\">Lemon</a>, <a href=\"http://archiveofourown.org/tags/Fluff\">Fluff</a>, <a href=\"http://archiveofourown.org/tags/Domestic%20Fluff\">Domestic Fluff</a>, <a href=\"http://archiveofourown.org/tags/Humor\">Humor</a>, <a href=\"http://archiveofourown.org/tags/Fluff%20and%20Humor\">Fluff and Humor</a>, <a href=\"http://archiveofourown.org/tags/bookverse\">bookverse</a>, <a href=\"http://archiveofourown.org/tags/Established%20Relationship\">Established Relationship</a></dd>\n",
      "29\n",
      "\n",
      "\n",
      "30\n",
      "<dt>Stats:</dt>\n",
      "31\n",
      "\n",
      "\n",
      "32\n",
      "<dd>\n",
      "        Published: 2020-06-16\n",
      "        Words: 665\n",
      "      </dd>\n",
      "33\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(soup.find(class_=\"tags\")) == 33:\n",
    "    fandom = extractFandoms(soup)\n",
    "    tags = extractAddTags(soup)\n",
    "    rating = extractStoryRating(soup)\n",
    "    warning = extractArchiveWarning(soup)\n",
    "    category = extractCategory(soup)\n",
    "    characters = extractCharacters(soup)\n",
    "    pub_stat = extractPubStats(soup) #publish_date, word_count\n",
    "\n",
    "elif len(soup.find(class_=\"tags\")) == 37:\n",
    "    fandom = extractFandoms(soup)\n",
    "    tags = extractAddTags(soup)\n",
    "    rating = extractStoryRating(soup)\n",
    "    warning = extractArchiveWarning(soup)\n",
    "    category = extractCategory(soup)\n",
    "    characters = extractCharacters(soup)\n",
    "    series = extractSeries(soup)\n",
    "    collections = extractCollections(soup)\n",
    "    pub_stat = extractPubStats(soup)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "character, fandom_text, additionalTags_text, story_rating, story_archive_warning, story_category, story_series_name, story_collections, story_publish_date, story_word_count = extractTags(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-04-28'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAuthor(soup_obj):\n",
    "    #code to extract author and fandom info\n",
    "    for info in soup_obj.title:\n",
    "        incomplete_title, author, incomplete_fandom = str(info).split('-')\n",
    "        author = author.strip()\n",
    "    return author\n",
    "    \n",
    "\n",
    "def extractTitleStory(soup_obj):\n",
    "    #code to extract title and story text\n",
    "    i = 0\n",
    "    story_text = \"\"\n",
    "    for element in soup_obj.find(id=\"chapters\"):\n",
    "        if i == 1:\n",
    "            title = element.string\n",
    "        elif i == 3:\n",
    "            story_ptag_text = element.find_all('p')\n",
    "            for obj in story_ptag_text:\n",
    "                if obj.string == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    story_text += str(obj.string) + \" \"\n",
    "        i += 1\n",
    "    return story_text\n",
    "        \n",
    "def extractTags(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    fandom_text = \"\"\n",
    "    additionalTags_text = \"\"\n",
    "    for element in soup_obj.find(class_=\"tags\"):\n",
    "        if i == 3:\n",
    "            story_rating = element.string\n",
    "        elif i == 7:\n",
    "            story_archive_warning = element.string\n",
    "        elif i == 11:\n",
    "            story_category = element.string\n",
    "        elif i == 15:\n",
    "            raw_fandom_text = element.find_all('a')\n",
    "            for obj in raw_fandom_text:\n",
    "                fandom_text += obj.string + \", \"\n",
    "            fandom_text = fandom_text[:-2]\n",
    "        elif i == 19:\n",
    "            story_character = element.string\n",
    "        elif i == 23:\n",
    "            additionalTags = element.find_all('a')\n",
    "            for obj in additionalTags:\n",
    "                additionalTags_text += obj.string + \", \"\n",
    "            additionalTags_text = additionalTags_text[:-2]\n",
    "        elif i == 27:\n",
    "            story_series_name = element.find('a').string\n",
    "        elif i == 31:\n",
    "            story_collections = element.string\n",
    "        elif i == 35:\n",
    "            pub_stat = str(element.string).strip()\n",
    "            story_publish_date = pub_stat[11:21]\n",
    "            story_word_count = pub_stat[37:40]\n",
    "        i += 1\n",
    "   \n",
    "    return story_character, fandom_text, additionalTags_text, story_rating, story_archive_warning, story_category, story_series_name, story_collections, story_publish_date, story_word_count\n",
    "\n",
    "def extractStoryURL(soup_obj): \n",
    "    #code to extract story URL\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"message\"):\n",
    "        i += 1\n",
    "        if i == 7:\n",
    "            url = element['href']\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    return url\n",
    "\n",
    "def createAO3dict(filelist):\n",
    "    i = 0\n",
    "    ao3_dict = {}\n",
    "    for element in filelist:\n",
    "        soup = BeautifulSoup(open(element), \"html.parser\")\n",
    "        url = extractStoryURL(soup)\n",
    "        story_text = extractTitleStory(soup)\n",
    "        character, fandom_text, additionalTags_text, rating, archive_warning, category, series_name, collections, pub_date, word_count = extractTags(soup)\n",
    "        author = extractAuthor(soup)\n",
    "        title = extractTitleStory(soup)\n",
    "        \n",
    "        story_dict = {'title': title,\n",
    "            'author': author,\n",
    "            'story_text': story_text, \n",
    "            'rating': rating, \n",
    "            'archive_warning': archive_warning, \n",
    "            'category': category, \n",
    "            'fandom_text': fandom_text, \n",
    "            'character': character, \n",
    "            'additionalTags_text': additionalTags_text, \n",
    "            'series_name': series_name, \n",
    "            'collections': collections, \n",
    "            'pub_date': pub_date, \n",
    "            'word_count': word_count,\n",
    "            'url': url\n",
    "           }\n",
    "        ao3_dict['i'] = story_dict\n",
    "        i += 1\n",
    "    return ao3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fanfics = ['Fanfic_HTML/13 Heirs.html', 'Fanfic_HTML/In Which A Wizard Comes.html', 'Fanfic_HTML/Sweet Basil and Italian.html', \n",
    "           'Fanfic_HTML/5 6 7 The Umbrella.html', 'Fanfic_HTML/In Which A Wizard Is.html', 'Fanfic_HTML/Swine and Forests.html',\n",
    "           'Fanfic_HTML/50 Truths of the.html', 'Fanfic_HTML/In Which Calcifer Meets.html', 'Fanfic_HTML/Symbol of Reform.html',\n",
    "           'Fanfic_HTML/A Bakers Proposal.html', 'Fanfic_HTML/In Which Howl Attracts.html', 'Fanfic_HTML/Sympathy.html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'story_publish_date' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-883e0f0dce97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mao3_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateAO3dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfanfics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-db25e1231fbb>\u001b[0m in \u001b[0;36mcreateAO3dict\u001b[0;34m(filelist)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractStoryURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mstory_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractTitleStory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mcharacter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfandom_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditionalTags_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_warning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpub_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractAuthor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractTitleStory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-db25e1231fbb>\u001b[0m in \u001b[0;36mextractTags\u001b[0;34m(soup_obj)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstory_character\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfandom_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditionalTags_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_archive_warning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_series_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_collections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_publish_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstory_word_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextractStoryURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'story_publish_date' referenced before assignment"
     ]
    }
   ],
   "source": [
    "ao3_dictionary = createAO3dict(fanfics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao3_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>00.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>verybi_verytired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story_text</th>\n",
       "      <td>He was hungry. Always so hungry. He wasn’t exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>General Audiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive_warning</th>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fandom_text</th>\n",
       "      <td>The Umbrella Academy (TV), The Umbrella Academ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>Number Five | The Boy (Umbrella Academy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additionalTags_text</th>\n",
       "      <td>Eating Disorders, Eating Disorder Not Otherwis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_name</th>\n",
       "      <td>Angsty Headcanon Ficlets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections</th>\n",
       "      <td>Bad Things Happen Bingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_date</th>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>http://archiveofourown.org/works/18632218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0\n",
       "title                                                            00.05\n",
       "author                                                verybi_verytired\n",
       "story_text           He was hungry. Always so hungry. He wasn’t exa...\n",
       "rating                                               General Audiences\n",
       "archive_warning                     Choose Not To Use Archive Warnings\n",
       "category                                                           Gen\n",
       "fandom_text          The Umbrella Academy (TV), The Umbrella Academ...\n",
       "character                     Number Five | The Boy (Umbrella Academy)\n",
       "additionalTags_text  Eating Disorders, Eating Disorder Not Otherwis...\n",
       "series_name                                   Angsty Headcanon Ficlets\n",
       "collections                                    Bad Things Happen Bingo\n",
       "pub_date                                                    2019-04-28\n",
       "word_count                                                         327\n",
       "url                          http://archiveofourown.org/works/18632218"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df = pd.DataFrame.from_dict(ao3_data)\n",
    "ao3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"00.05\",\n",
      "    \"author\": \"verybi_verytired\",\n",
      "    \"story_text\": \"He was hungry. Always so hungry. He wasn\\u2019t exactly sure why he was doing this to himself. He didn\\u2019t want or need to lose weight, there was always plenty of food, and everyone else was well fed and happy. So why couldn\\u2019t he bring himself to eat? During the apocalypse, he barely ate. It was rare that he was full, and when he was full he tended to get sick, his stomach not used to the amount of food in it. Within a year or two of arriving in the ruins of the city, he was used to passing out from a lack of food or water. After he started working as a time travelling assassin he thought it would get better. He was wrong. For some reason, even when literally surrounded by food, he found himself sick at the idea of eating it. Food tasted too good, too strong and it felt weird in his mouth, the textures too much for him to handle. The weight of it in his stomach made him want to curl up or get sick \\u2013 more than once he\\u2019d had to make himself throw up when that feeling got too strong. Getting back to his family, in his 13-year-old body, didn\\u2019t seem to help either. The only real difference was that this body felt the hunger in a way that he hadn\\u2019t experienced since the start of the apocalypse, years ago. He hated this. Hated that he couldn\\u2019t eat without panicking or throwing up. That he couldn\\u2019t eat without it feeling wrong. And yet this body ached to be fed and he felt sick when he didn\\u2019t eat. So he drank. A lot. Too much, really. It wasn\\u2019t exactly healthy, but at least he was consuming some calories, and after a drink or two he was usually numb enough that he could even get down a small amount of food. It wasn\\u2019t much but it was better than nothing, right? Right? \",\n",
      "    \"rating\": \"General Audiences\",\n",
      "    \"archive_warning\": \"Choose Not To Use Archive Warnings\",\n",
      "    \"category\": \"Gen\",\n",
      "    \"fandom_text\": \"The Umbrella Academy (TV), The Umbrella Academy (Comics)\",\n",
      "    \"character\": \"Number Five | The Boy (Umbrella Academy)\",\n",
      "    \"additionalTags_text\": \"Eating Disorders, Eating Disorder Not Otherwise Specified, Implied/Referenced Alcohol Abuse/Alcoholism, no beta we die like men\",\n",
      "    \"series_name\": \"Angsty Headcanon Ficlets\",\n",
      "    \"collections\": \"Bad Things Happen Bingo\",\n",
      "    \"pub_date\": \"2019-04-28\",\n",
      "    \"word_count\": \"327\",\n",
      "    \"url\": \"http://archiveofourown.org/works/18632218\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#code from https://www.geeksforgeeks.org/how-to-convert-python-dictionary-to-json/    \n",
    "# Serializing json    \n",
    "json_object = json.dumps(ao3_data, indent = 4)   \n",
    "print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-fc42e8a8cad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mao3_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             self.obj = DataFrame(\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         ]\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "ao3_df = pd.read_json(json_object, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>00.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>verybi_verytired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story_text</th>\n",
       "      <td>He was hungry. Always so hungry. He wasn’t exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>General Audiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archive_warning</th>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Gen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fandom_text</th>\n",
       "      <td>[The Umbrella Academy (TV), The Umbrella Acade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>Number Five | The Boy (Umbrella Academy)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additionalTags_text</th>\n",
       "      <td>[Eating Disorders, Eating Disorder Not Otherwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_name</th>\n",
       "      <td>Angsty Headcanon Ficlets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections</th>\n",
       "      <td>Bad Things Happen Bingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_date</th>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>http://archiveofourown.org/works/18632218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0\n",
       "title                                                            00.05\n",
       "author                                                verybi_verytired\n",
       "story_text           He was hungry. Always so hungry. He wasn’t exa...\n",
       "rating                                               General Audiences\n",
       "archive_warning                     Choose Not To Use Archive Warnings\n",
       "category                                                           Gen\n",
       "fandom_text          [The Umbrella Academy (TV), The Umbrella Acade...\n",
       "character                     Number Five | The Boy (Umbrella Academy)\n",
       "additionalTags_text  [Eating Disorders, Eating Disorder Not Otherwi...\n",
       "series_name                                   Angsty Headcanon Ficlets\n",
       "collections                                    Bad Things Happen Bingo\n",
       "pub_date                                                    2019-04-28\n",
       "word_count                                                         327\n",
       "url                          http://archiveofourown.org/works/18632218"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None of [None] are in the columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-8271a857d260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mao3_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, index, columns, values)\u001b[0m\n\u001b[1;32m   5921\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5923\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5925\u001b[0m     _shared_docs[\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, index, columns, values)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None of [None] are in the columns'"
     ]
    }
   ],
   "source": [
    "ao3_df.pivot(index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Umbrella Academy (TV)', 'The Umbrella Academy (Comics)']\n"
     ]
    }
   ],
   "source": [
    "print(fandom_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
