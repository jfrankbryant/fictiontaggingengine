{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fanfics = os.listdir('Fanfic_HTML')\n",
    "\n",
    "remove_fanfics = ['.DS_Store', 'New Beginnings AU.html', 'Book Commentary The Book.html', 'Google Reads Fanfics.html', 'Overheated.html', 'The Internet Is Forever.html', 'Bound.html']\n",
    "for item in remove_fanfics:\n",
    "    fanfics.remove(item)\n",
    "\n",
    "for index, item in enumerate(fanfics):\n",
    "    fanfics[index] = 'Fanfic_HTML/' + item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractStoryRating(classTags):\n",
    "    #code to extract story rating\n",
    "    i = 0\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if i == 4:\n",
    "            story_rating = str(element.find('a').string)\n",
    "        elif i > 4:\n",
    "            break\n",
    "            \n",
    "    return story_rating\n",
    "\n",
    "def extractArchiveWarning(classTags):\n",
    "    i = 0\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if i == 8:\n",
    "            archiveWarning = str(element.find('a').string)\n",
    "        elif i > 8:\n",
    "            break\n",
    "            \n",
    "    return archiveWarning\n",
    "\n",
    "def extractCategory(classTags):\n",
    "    #code to extract category\n",
    "    i = 0\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if i == 12:\n",
    "            story_category = str(element.find('a').string)\n",
    "        elif i > 12:\n",
    "            break\n",
    "\n",
    "    return story_category\n",
    "\n",
    "def extractFandoms(classTags):\n",
    "    #code to extract fandoms\n",
    "    i = 0\n",
    "    j = 0\n",
    "    fandom_text = \"\"\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Fandom:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            raw_fandom_text = element.find_all('a')\n",
    "            for obj in raw_fandom_text:\n",
    "                fandom_text += str(obj.string) + ', '\n",
    "            fandom_text = fandom_text[:-2]\n",
    "\n",
    "    return fandom_text\n",
    "\n",
    "def extractRelationships(classTags):\n",
    "    #code to extract relationships\n",
    "    i = 0\n",
    "    j = 0\n",
    "    story_relationships = \"\"\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Relationship:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            raw_relationships = element.find_all('a')\n",
    "            for obj in raw_relationships:\n",
    "                story_relationships += str(obj.string) + ', '\n",
    "            story_relationships = story_relationships[:-2]\n",
    "            \n",
    "    return story_relationships\n",
    "\n",
    "def extractCharacters(classTags):\n",
    "    #code to extract characters\n",
    "    i = 0\n",
    "    j = 0\n",
    "    characters = \"\"\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Character:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            raw_characters = element.find_all('a')\n",
    "            for obj in raw_characters:\n",
    "                characters += str(obj.string) + ', '\n",
    "            characters = characters[:-2]\n",
    "            \n",
    "    return characters\n",
    "\n",
    "def extractAddTags(classTags):\n",
    "    #code to extract tags\n",
    "    i = 0\n",
    "    j = 0\n",
    "    additionalTags_text = \"\"\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Additional Tags:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            additionalTags = element.find_all('a')\n",
    "            for obj in additionalTags:\n",
    "                additionalTags_text += str(obj.string) + ', '\n",
    "            additionalTags_text = additionalTags_text[:-2]\n",
    "\n",
    "    return additionalTags_text\n",
    "\n",
    "def extractSeries(classTags):\n",
    "    #code to extract publication stats\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Series:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            series = str(element.find('a').string)\n",
    "\n",
    "    return series\n",
    "\n",
    "def extractCollections(classTags):\n",
    "    #code to extract publication stats\n",
    "    i = 0\n",
    "    j = 0\n",
    "    collections = \"\"\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Collections:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            collections = str(element.find('a').string)\n",
    "\n",
    "    return collections\n",
    "\n",
    "def extractPubStats(classTags):\n",
    "    #code to extract publication stats\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for element in classTags:\n",
    "        i += 1\n",
    "        if str(element.string) == \"Stats:\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            pub_stat = str(element.string).strip()\n",
    "            stat_length = len(pub_stat)\n",
    "            story_publish_date = pub_stat[11:21]\n",
    "            story_word_count = pub_stat[stat_length-4:stat_length+1]\n",
    "            if \" \" not in story_word_count:\n",
    "                continue\n",
    "            else: \n",
    "                story_word_count = story_word_count[1:]\n",
    "    \n",
    "    return story_publish_date, story_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTags(soup_obj):\n",
    "    #code to extract metadata (fandom, characters, tags, warning, etc.)\n",
    "    i = 0\n",
    "    fandom_text = np.nan\n",
    "    story_character = np.nan\n",
    "    relationship = np.nan\n",
    "    addTags = np.nan\n",
    "    archiveWarning = np.nan\n",
    "    category = np.nan\n",
    "    fandoms = np.nan\n",
    "    pubDate = np.nan\n",
    "    series = np.nan\n",
    "    collections = np.nan\n",
    "    wordCount = np.nan\n",
    "    tagsClass = soup_obj.find(class_=\"tags\")\n",
    "    for element in tagsClass:\n",
    "        if str(element.string) == \"Rating:\":\n",
    "            rating = extractStoryRating(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Archive Warning:\":\n",
    "            archiveWarning = extractArchiveWarning(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Category:\":\n",
    "            category = extractCategory(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Fandom:\":\n",
    "            fandom_text = extractFandoms(tagsClass)\n",
    "        \n",
    "        elif str(element.string) == \"Relationship:\":\n",
    "            relationship = extractRelationships(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Character:\":\n",
    "            story_character = extractCharacters(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Additional Tags:\":\n",
    "            addTags = extractAddTags(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Series:\":\n",
    "            series = extractSeries(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Collections:\":\n",
    "            collections = extractCollections(tagsClass)\n",
    "            \n",
    "        elif str(element.string) == \"Stats:\":\n",
    "            pubDate, wordCount = extractPubStats(tagsClass)\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    local_tag_dict = {'rating' : rating,\n",
    "                'archiveWarnings': archiveWarning,\n",
    "                'category' : category,\n",
    "                'fandom' : fandom_text,\n",
    "                'relationships' : relationship,\n",
    "                'character': story_character,\n",
    "                'additionalTags': addTags,  \n",
    "                'series': series, \n",
    "                'collections': collections,\n",
    "                'pub_date' : pubDate, \n",
    "                'word_count' : wordCount\n",
    "               }\n",
    "        \n",
    "    return local_tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAuthor(soup_obj):\n",
    "    #code to extract author and fandom info\n",
    "    for info in soup_obj.title:\n",
    "        author = str(info).split('-')[1]\n",
    "        author = author.strip()\n",
    "    return author\n",
    "\n",
    "def extractTitle(soup_obj):\n",
    "    #code to extract title\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"message\"):\n",
    "        if i == 1:\n",
    "            title = element.string\n",
    "        elif i > 1:\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    return title\n",
    "    \n",
    "def extractStory(soup_obj):\n",
    "    #code to extract title and story text\n",
    "    i = 0\n",
    "    story_text = \"\"\n",
    "    for element in soup_obj.find(id=\"chapters\"):\n",
    "        if i == 3:\n",
    "            if \"<span>\" in str(soup_obj):\n",
    "                story_spantag_text = element.find_all('span')\n",
    "                for obj in story_spantag_text:\n",
    "                    if obj.string == None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        story_text += str(obj.string) + \" \"\n",
    "                        \n",
    "            elif \"<div>\" in str(soup_obj):\n",
    "                story_divtag_text = element.find('div')\n",
    "                story_ptag_text = story_divtag_text.find_all('p')\n",
    "                for obj in story_ptag_text:\n",
    "                    features = obj.contents\n",
    "                    for feature in features:\n",
    "                        if \"br\" in str(feature):\n",
    "                            continue\n",
    "                        else:\n",
    "                            story_text += str(feature) + \" \" \n",
    "                            story_text = story_text.replace(\"<i>\", \"\")\n",
    "                            story_text = story_text.replace(\"</i>\", \"\")\n",
    "                        \n",
    "            else:\n",
    "                story_ptag_text = element.find_all('p')\n",
    "                if len(story_ptag_text) == 1:\n",
    "                    story_text = str(element.find('p'))\n",
    "                    story_text = story_text.replace(\"<p>\", \"\")\n",
    "                    story_text = story_text.replace(\"</p>\", \"\")\n",
    "                    story_text = story_text.replace(\"<br/>\", \"\")\n",
    "                else:\n",
    "                    for obj in story_ptag_text:\n",
    "                        if obj.string == None:\n",
    "                            continue\n",
    "                        else:\n",
    "                            story_text += str(obj.string) + \" \"\n",
    "                       \n",
    "        elif i > 3:\n",
    "            break\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    return story_text\n",
    "\n",
    "\n",
    "def extractStoryChapters(soup_obj):\n",
    "    #code to extract title and story text\n",
    "    i = 0\n",
    "    j = 0\n",
    "    story_chapter_text = \"\"\n",
    "    chapters = soup_obj.find(id=\"chapters\")\n",
    "    for element in soup_obj.find(id=\"chapters\"):\n",
    "        i += 1\n",
    "        if str(element.string) == \"chapter content\":\n",
    "            j = 2 + i\n",
    "        elif str(element.string) == \"/chapter content\":\n",
    "            j = 2 + i\n",
    "        elif i == j:\n",
    "            if 'blockquote class=\"userstuff\"' in str(chapters.find(class_=\"userstuff\")):\n",
    "                k = 0\n",
    "                m = 0\n",
    "                for element in chapters:\n",
    "                    k += 1\n",
    "                    if str(element.string) == \"chapter content\":\n",
    "                        m = 2 + k\n",
    "                    elif k == m:\n",
    "                        chapter_ptag_text = element.find_all('p')\n",
    "                        \n",
    "            elif \"<span>\" in str(chapters.find(class_=\"userstuff\")):\n",
    "                n = 0\n",
    "                o = 0\n",
    "                for element in chapters:\n",
    "                    n += 1\n",
    "                    if str(element.string) == \"chapter content\":\n",
    "                        o = 2 + n\n",
    "                    elif n == o:\n",
    "                        chapter_ptag_text = element.find_all('span')\n",
    "                        \n",
    "            else:\n",
    "                userStuff = chapters.find(class_=\"userstuff\")\n",
    "                chapter_ptag_text = userStuff.find_all('p')\n",
    "                \n",
    "            for obj in chapter_ptag_text:\n",
    "                if obj.string == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    story_chapter_text += str(obj.string) + \" \"\n",
    "                    \n",
    "    return story_chapter_text\n",
    "\n",
    "def extractStoryURL(soup_obj): \n",
    "    #code to extract story URL\n",
    "    i = 0\n",
    "    for element in soup_obj.find(class_=\"message\"):\n",
    "        i += 1\n",
    "        if i == 7:\n",
    "            url = element['href']\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    return url\n",
    "\n",
    "def createAO3dict(filelist):\n",
    "    i = 0\n",
    "    ao3_dict = {}\n",
    "    for element in filelist:\n",
    "        soup = BeautifulSoup(open(element), \"html.parser\")\n",
    "        url = extractStoryURL(soup)\n",
    "        tag_dict = extractTags(soup)\n",
    "        author = extractAuthor(soup)\n",
    "        title = extractTitle(soup)\n",
    "        if \"chapter content\" in str(soup):\n",
    "            story_text = extractStoryChapters(soup)\n",
    "        else:\n",
    "            story_text = extractStory(soup)\n",
    "        \n",
    "        story_dict = {'title': title,\n",
    "                      'author': author,\n",
    "                      'story_text': story_text, \n",
    "                      'url': url,\n",
    "                     }\n",
    "        story_dict.update(tag_dict)\n",
    "        \n",
    "        ao3_dict[i] = story_dict\n",
    "        i += 1\n",
    "    return ao3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ao3_dictionary = createAO3dict(fanfics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>story_text</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "      <th>archiveWarnings</th>\n",
       "      <th>category</th>\n",
       "      <th>fandom</th>\n",
       "      <th>relationships</th>\n",
       "      <th>character</th>\n",
       "      <th>additionalTags</th>\n",
       "      <th>series</th>\n",
       "      <th>collections</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Too Many Accidents</td>\n",
       "      <td>kazesuke</td>\n",
       "      <td>“Sophiiiieee!!!” Loud, wet footsteps slammed a...</td>\n",
       "      <td>http://archiveofourown.org/works/299981</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Howl no Ugoku Shiro | Howl's Moving Castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Howl Pendragon, Sophie, Markl, Calcifer (Howl ...</td>\n",
       "      <td>Genderbending</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yuletide 2011</td>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Life Plan</td>\n",
       "      <td>Anonfandom101</td>\n",
       "      <td>Life. ( A brief albeit important prolouge )\\n\\...</td>\n",
       "      <td>http://archiveofourown.org/works/19198501</td>\n",
       "      <td>Teen And Up Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>F/F</td>\n",
       "      <td>Hitchhiker's Guide to the Galaxy - Douglas Ada...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Recurse</td>\n",
       "      <td>orphan_account</td>\n",
       "      <td>No one of them could be Cindi Mayweather. It's...</td>\n",
       "      <td>http://archiveofourown.org/works/333825</td>\n",
       "      <td>Mature</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>F/F</td>\n",
       "      <td>Metropolis: The Chase Suite - Janelle Monáe, T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alpha 9000s, Cindi Mayweather</td>\n",
       "      <td>Androids, Clones, Character of Color, Porn Battle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porn Battle XIII (Lucky Thirteen)</td>\n",
       "      <td>2012-02-06</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask, and ye shall receive</td>\n",
       "      <td>Ariaste</td>\n",
       "      <td>He feels rather daring about it, especially wh...</td>\n",
       "      <td>http://archiveofourown.org/works/19964368</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>M/M</td>\n",
       "      <td>Good Omens (TV), Good Omens - Neil Gaiman &amp; Te...</td>\n",
       "      <td>Aziraphale/Crowley (Good Omens)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a tiny accidental fic, cute and sweet, puns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Favorite Ineffable Husband Fics</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In Gardens</td>\n",
       "      <td>Bitterblue</td>\n",
       "      <td>Neither  of them is sure how to start, but Bit...</td>\n",
       "      <td>http://archiveofourown.org/works/432750</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Bitterblue - Kristin Cashore, Seven Kingdoms T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hava (Bitterblue), Bitterblue (Graceling)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-13</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Exchange</td>\n",
       "      <td>swiddershins</td>\n",
       "      <td>He’d inquired about the coat’s price, carefull...</td>\n",
       "      <td>http://archiveofourown.org/works/14392434</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Gen</td>\n",
       "      <td>Neverwhere - Neil Gaiman, Neverwhere - All Med...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marquis de Carabas (Neverwhere)</td>\n",
       "      <td>baby marquis, baby baby baby marquis, Characte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Peeta Mellark: In it to Survive</td>\n",
       "      <td>SilverTonguedWriter</td>\n",
       "      <td>The games were tomorrow. I had no fall back pl...</td>\n",
       "      <td>http://archiveofourown.org/works/1000334</td>\n",
       "      <td>Mature</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>M/M</td>\n",
       "      <td>Hunger Games Trilogy - Suzanne Collins</td>\n",
       "      <td>Cato/Peeta Mellark</td>\n",
       "      <td>Cato (Hunger Games), Peeta Mellark</td>\n",
       "      <td>One Shot, Sex, Blow Jobs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-11</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Keeping Promises</td>\n",
       "      <td>fourredfruits</td>\n",
       "      <td>Everything happened so fast it seemed like the...</td>\n",
       "      <td>http://archiveofourown.org/works/18372194</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>F/M</td>\n",
       "      <td>The Umbrella Academy (TV), The Umbrella Academ...</td>\n",
       "      <td>Number Five | The Boy &amp; Vanya Hargreeves, Numb...</td>\n",
       "      <td>Number Five | The Boy (Umbrella Academy), Vany...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Interlude: It grows back</td>\n",
       "      <td>kaleigh</td>\n",
       "      <td></td>\n",
       "      <td>http://archiveofourown.org/works/21219572</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>F/F</td>\n",
       "      <td>Addams Family - All Media Types, Addams Family...</td>\n",
       "      <td>Wednesday Addams/Original Female Character(s)</td>\n",
       "      <td>Wednesday Addams, Pubert Addams, Lurch (Addams...</td>\n",
       "      <td>Haircuts, Sibling Bonding</td>\n",
       "      <td>Love is a four letter word</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Partnership</td>\n",
       "      <td>roguefaerie</td>\n",
       "      <td>Sometimes Winchester thought about what other ...</td>\n",
       "      <td>http://archiveofourown.org/works/21432643</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supernatural, American Gods - Neil Gaiman</td>\n",
       "      <td>Shadow Moon (American Gods)/Dean Winchester</td>\n",
       "      <td>Dean Winchester, Shadow Moon (American Gods)</td>\n",
       "      <td>Queerplatonic Relationships, Established Relat...</td>\n",
       "      <td>Finding Home Away From Home (GQ/Enby Dean Winc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-14</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title               author  \\\n",
       "0              One Too Many Accidents             kazesuke   \n",
       "1                       The Life Plan        Anonfandom101   \n",
       "2                         One Recurse       orphan_account   \n",
       "3           ask, and ye shall receive              Ariaste   \n",
       "4                          In Gardens           Bitterblue   \n",
       "...                               ...                  ...   \n",
       "1039                         Exchange         swiddershins   \n",
       "1040  Peeta Mellark: In it to Survive  SilverTonguedWriter   \n",
       "1041                 Keeping Promises        fourredfruits   \n",
       "1042         Interlude: It grows back              kaleigh   \n",
       "1043                      Partnership          roguefaerie   \n",
       "\n",
       "                                             story_text  \\\n",
       "0     “Sophiiiieee!!!” Loud, wet footsteps slammed a...   \n",
       "1     Life. ( A brief albeit important prolouge )\\n\\...   \n",
       "2     No one of them could be Cindi Mayweather. It's...   \n",
       "3     He feels rather daring about it, especially wh...   \n",
       "4     Neither  of them is sure how to start, but Bit...   \n",
       "...                                                 ...   \n",
       "1039  He’d inquired about the coat’s price, carefull...   \n",
       "1040  The games were tomorrow. I had no fall back pl...   \n",
       "1041  Everything happened so fast it seemed like the...   \n",
       "1042                                                      \n",
       "1043  Sometimes Winchester thought about what other ...   \n",
       "\n",
       "                                            url                 rating  \\\n",
       "0       http://archiveofourown.org/works/299981      General Audiences   \n",
       "1     http://archiveofourown.org/works/19198501  Teen And Up Audiences   \n",
       "2       http://archiveofourown.org/works/333825                 Mature   \n",
       "3     http://archiveofourown.org/works/19964368      General Audiences   \n",
       "4       http://archiveofourown.org/works/432750      General Audiences   \n",
       "...                                         ...                    ...   \n",
       "1039  http://archiveofourown.org/works/14392434      General Audiences   \n",
       "1040   http://archiveofourown.org/works/1000334                 Mature   \n",
       "1041  http://archiveofourown.org/works/18372194      General Audiences   \n",
       "1042  http://archiveofourown.org/works/21219572              Not Rated   \n",
       "1043  http://archiveofourown.org/works/21432643      General Audiences   \n",
       "\n",
       "                         archiveWarnings category  \\\n",
       "0              No Archive Warnings Apply      Gen   \n",
       "1              No Archive Warnings Apply      F/F   \n",
       "2              No Archive Warnings Apply      F/F   \n",
       "3              No Archive Warnings Apply      M/M   \n",
       "4              No Archive Warnings Apply      Gen   \n",
       "...                                  ...      ...   \n",
       "1039           No Archive Warnings Apply      Gen   \n",
       "1040  Choose Not To Use Archive Warnings      M/M   \n",
       "1041  Choose Not To Use Archive Warnings      F/M   \n",
       "1042           No Archive Warnings Apply      F/F   \n",
       "1043           No Archive Warnings Apply    Other   \n",
       "\n",
       "                                                 fandom  \\\n",
       "0            Howl no Ugoku Shiro | Howl's Moving Castle   \n",
       "1     Hitchhiker's Guide to the Galaxy - Douglas Ada...   \n",
       "2     Metropolis: The Chase Suite - Janelle Monáe, T...   \n",
       "3     Good Omens (TV), Good Omens - Neil Gaiman & Te...   \n",
       "4     Bitterblue - Kristin Cashore, Seven Kingdoms T...   \n",
       "...                                                 ...   \n",
       "1039  Neverwhere - Neil Gaiman, Neverwhere - All Med...   \n",
       "1040             Hunger Games Trilogy - Suzanne Collins   \n",
       "1041  The Umbrella Academy (TV), The Umbrella Academ...   \n",
       "1042  Addams Family - All Media Types, Addams Family...   \n",
       "1043          Supernatural, American Gods - Neil Gaiman   \n",
       "\n",
       "                                          relationships  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                       Aziraphale/Crowley (Good Omens)   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1039                                                NaN   \n",
       "1040                                 Cato/Peeta Mellark   \n",
       "1041  Number Five | The Boy & Vanya Hargreeves, Numb...   \n",
       "1042      Wednesday Addams/Original Female Character(s)   \n",
       "1043        Shadow Moon (American Gods)/Dean Winchester   \n",
       "\n",
       "                                              character  \\\n",
       "0     Howl Pendragon, Sophie, Markl, Calcifer (Howl ...   \n",
       "1                                                   NaN   \n",
       "2                         Alpha 9000s, Cindi Mayweather   \n",
       "3                                                   NaN   \n",
       "4             Hava (Bitterblue), Bitterblue (Graceling)   \n",
       "...                                                 ...   \n",
       "1039                    Marquis de Carabas (Neverwhere)   \n",
       "1040                 Cato (Hunger Games), Peeta Mellark   \n",
       "1041  Number Five | The Boy (Umbrella Academy), Vany...   \n",
       "1042  Wednesday Addams, Pubert Addams, Lurch (Addams...   \n",
       "1043       Dean Winchester, Shadow Moon (American Gods)   \n",
       "\n",
       "                                         additionalTags  \\\n",
       "0                                         Genderbending   \n",
       "1                                                   NaN   \n",
       "2     Androids, Clones, Character of Color, Porn Battle   \n",
       "3           a tiny accidental fic, cute and sweet, puns   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1039  baby marquis, baby baby baby marquis, Characte...   \n",
       "1040                           One Shot, Sex, Blow Jobs   \n",
       "1041                                                NaN   \n",
       "1042                          Haircuts, Sibling Bonding   \n",
       "1043  Queerplatonic Relationships, Established Relat...   \n",
       "\n",
       "                                                 series  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1039                                                NaN   \n",
       "1040                                                NaN   \n",
       "1041                                                NaN   \n",
       "1042                         Love is a four letter word   \n",
       "1043  Finding Home Away From Home (GQ/Enby Dean Winc...   \n",
       "\n",
       "                             collections    pub_date word_count  \n",
       "0                          Yuletide 2011  2011-12-22       1071  \n",
       "1                                    NaN  2019-06-15        750  \n",
       "2      Porn Battle XIII (Lucky Thirteen)  2012-02-06        889  \n",
       "3     My Favorite Ineffable Husband Fics  2019-07-24        441  \n",
       "4                                    NaN  2012-06-13        279  \n",
       "...                                  ...         ...        ...  \n",
       "1039                                 NaN  2018-04-22        759  \n",
       "1040                                 NaN  2013-10-11        444  \n",
       "1041                                 NaN  2019-04-06        808  \n",
       "1042                                 NaN  2019-10-29        959  \n",
       "1043                                 NaN  2019-11-14        100  \n",
       "\n",
       "[1044 rows x 15 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df = pd.DataFrame.from_dict(ao3_dictionary, orient=\"index\")\n",
    "ao3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1071\n",
       "1        750\n",
       "2        889\n",
       "3        441\n",
       "4        279\n",
       "        ... \n",
       "1039     759\n",
       "1040     444\n",
       "1041     808\n",
       "1042     959\n",
       "1043     100\n",
       "Name: word_count, Length: 1044, dtype: int32"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df.word_count.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows where story_text is a blank string, for now\n",
    "blankStory_df = ao3_df[ao3_df[\"story_text\"] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>story_text</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "      <th>archiveWarnings</th>\n",
       "      <th>category</th>\n",
       "      <th>fandom</th>\n",
       "      <th>relationships</th>\n",
       "      <th>character</th>\n",
       "      <th>additionalTags</th>\n",
       "      <th>series</th>\n",
       "      <th>collections</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, author, story_text, url, rating, archiveWarnings, category, fandom, relationships, character, additionalTags, series, collections, pub_date, word_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df = ao3_df.drop(blankStory_df.index)\n",
    "ao3_df[ao3_df[\"story_text\"] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>story_text</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "      <th>archiveWarnings</th>\n",
       "      <th>category</th>\n",
       "      <th>fandom</th>\n",
       "      <th>relationships</th>\n",
       "      <th>character</th>\n",
       "      <th>additionalTags</th>\n",
       "      <th>series</th>\n",
       "      <th>collections</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Overheated</td>\n",
       "      <td>Su_Whisterfield</td>\n",
       "      <td></td>\n",
       "      <td>http://archiveofourown.org/works/30107565</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>M/M</td>\n",
       "      <td>X-Men (Comicverse)</td>\n",
       "      <td>Logan/Kurt Wagner</td>\n",
       "      <td>Kurt Wagner, Logan (X-Men)</td>\n",
       "      <td>sauna sex, Tail Sex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03-17</td>\n",
       "      <td>: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>The Internet Is Forever</td>\n",
       "      <td>Miffy</td>\n",
       "      <td></td>\n",
       "      <td>http://archiveofourown.org/works/7310356</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>F/M</td>\n",
       "      <td>Hunger Games Trilogy - Suzanne Collins, Hunger...</td>\n",
       "      <td>Katniss Everdeen/Peeta Mellark, Annie Cresta/F...</td>\n",
       "      <td>Katniss Everdeen, Peeta Mellark, Primrose Ever...</td>\n",
       "      <td>Social Media, Fluff, Alternate Universe - Mode...</td>\n",
       "      <td>Blue Skies Are Coming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Bound</td>\n",
       "      <td>Rav3nB1ack</td>\n",
       "      <td>\\n&lt;iframe allowfullscreen=\"\" frameborder=\"0\" h...</td>\n",
       "      <td>http://archiveofourown.org/works/23647354</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>F/M</td>\n",
       "      <td>Pacific Rim (Movies), 47 Ronin (2013), King Ar...</td>\n",
       "      <td>Raleigh Becket/Mako Mori, Raleigh Becket &amp; Mak...</td>\n",
       "      <td>Mako Mori, Raleigh Becket, Arthur (King Arthur...</td>\n",
       "      <td>Fanvids, Alternate Universe, Alternate Univers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>: 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title           author  \\\n",
       "650               Overheated  Su_Whisterfield   \n",
       "768  The Internet Is Forever            Miffy   \n",
       "830                    Bound       Rav3nB1ack   \n",
       "\n",
       "                                            story_text  \\\n",
       "650                                                      \n",
       "768                                                      \n",
       "830  \\n<iframe allowfullscreen=\"\" frameborder=\"0\" h...   \n",
       "\n",
       "                                           url             rating  \\\n",
       "650  http://archiveofourown.org/works/30107565           Explicit   \n",
       "768   http://archiveofourown.org/works/7310356  General Audiences   \n",
       "830  http://archiveofourown.org/works/23647354  General Audiences   \n",
       "\n",
       "                        archiveWarnings category  \\\n",
       "650           No Archive Warnings Apply      M/M   \n",
       "768  Choose Not To Use Archive Warnings      F/M   \n",
       "830  Choose Not To Use Archive Warnings      F/M   \n",
       "\n",
       "                                                fandom  \\\n",
       "650                                 X-Men (Comicverse)   \n",
       "768  Hunger Games Trilogy - Suzanne Collins, Hunger...   \n",
       "830  Pacific Rim (Movies), 47 Ronin (2013), King Ar...   \n",
       "\n",
       "                                         relationships  \\\n",
       "650                                  Logan/Kurt Wagner   \n",
       "768  Katniss Everdeen/Peeta Mellark, Annie Cresta/F...   \n",
       "830  Raleigh Becket/Mako Mori, Raleigh Becket & Mak...   \n",
       "\n",
       "                                             character  \\\n",
       "650                         Kurt Wagner, Logan (X-Men)   \n",
       "768  Katniss Everdeen, Peeta Mellark, Primrose Ever...   \n",
       "830  Mako Mori, Raleigh Becket, Arthur (King Arthur...   \n",
       "\n",
       "                                        additionalTags                 series  \\\n",
       "650                                sauna sex, Tail Sex                    NaN   \n",
       "768  Social Media, Fluff, Alternate Universe - Mode...  Blue Skies Are Coming   \n",
       "830  Fanvids, Alternate Universe, Alternate Univers...                    NaN   \n",
       "\n",
       "    collections    pub_date word_count  \n",
       "650         NaN  2021-03-17        : 0  \n",
       "768         NaN  2016-06-26        : 0  \n",
       "830         NaN  2020-04-14        : 0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3_df.to_csv(\"ao3_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
